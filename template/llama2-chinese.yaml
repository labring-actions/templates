apiVersion: app.sealos.io/v1
kind: Template
metadata:
  name: llama2-chinese
spec:
  title: 'llama2-chinese'
  url: 'https://github.com/LinkSoul-AI/Chinese-Llama-2-7b'
  gitRepo: 'https://github.com/luanshaotong/text-generation-webui-docker.git'
  author: 'Sealos'
  description: '全部开源，完全可商用的中文版 Llama2 模型及中英文 SFT 数据集，输入格式严格遵循 llama-2-chat 格式，兼容适配所有针对原版 llama-2-chat 模型的优化。'
  readme: 'https://raw.githubusercontent.com/luanshaotong/text-generation-webui-docker/main/README.md'
  icon: 'https://raw.githubusercontent.com/LinkSoul-AI/Chinese-Llama-2-7b/main/.github/preview.jpg'
  templateType: inline
  locale: zh
  draft: true
  categories:
    - ai
  defaults:
    app_host:
      # number or string..
      type: string
      value: ${{ random(8) }}
    app_name:
      type: string
      value: llama2-chinese-${{ random(8) }}
  inputs:
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ${{ defaults.app_name }}
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}
    app: ${{ defaults.app_name }}
spec:
  accessModes:
    - ReadOnlyMany
  resources:
    requests:
      storage: 10Gi
  storageClassName: sealfs-csi-llama-chinese
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ${{ defaults.app_name }}
data:
  vn-appvn-charactersvn-instruction-followingvn-nonevn-yaml: |2-
        user: ""
        bot: ""
        turn_template: "<|user|><|user-message|> [/INST] <|bot|><|bot-message|> </s><s>[INST] "
        context: "[INST] <<SYS>>\nPlease answer all the questions in Chinese.\n<</SYS>>\n\n"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ${{ defaults.app_name }}
  annotations:
    originImageName: luanshaotong/text-generation-webui-cpu:dev
    deploy.cloud.sealos.io/minReplicas: '1'
    deploy.cloud.sealos.io/maxReplicas: '1'
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}
    app: ${{ defaults.app_name }}
spec:
  replicas: 1
  revisionHistoryLimit: 1
  selector:
    matchLabels:
      app: ${{ defaults.app_name }}
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 0
  serviceName: ${{ defaults.app_name }}
  template:
    metadata:
      labels:
        app: ${{ defaults.app_name }}
    spec:
      containers:
        - name: ${{ defaults.app_name }}
          image: luanshaotong/text-generation-webui-cpu:dev
          command: ["sh", "-c"]
          args: ["cp /share/models/* /app/models/ && /scripts/docker-entrypoint.sh python3 /app/server.py --listen --verbose --chat --model Chinese-Llama-2-7b-ggml-q4.bin --extensions openai --n_ctx 4096"]
          resources:
            requests:
              cpu: 2
              memory: 4Gi
            limits:
              cpu: 15
              memory: 8Gi
          ports:
            - containerPort: 5001
          volumeMounts:
            - name: models
              mountPath: "/share/models"
            - mountPath: /app/characters/instruction-following/None.yaml
              name: vn-appvn-charactersvn-instruction-followingvn-nonevn-yaml
              subPath: ./app/characters/instruction-following/None.yaml
      volumes:
        - name: models
          persistentVolumeClaim:
            claimName: ${{ defaults.app_name }}
        - configMap:
            defaultMode: 420
            items:
            - key: vn-appvn-charactersvn-instruction-followingvn-nonevn-yaml
              path: ./app/characters/instruction-following/None.yaml
            name: ${{ defaults.app_name }}
          name: vn-appvn-charactersvn-instruction-followingvn-nonevn-yaml
---
apiVersion: v1
kind: Service
metadata:
  name: ${{ defaults.app_name }}
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}
spec:
  ports:
    - port: 5001
  selector:
    app: ${{ defaults.app_name }}
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ${{ defaults.app_name }}
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}
    cloud.sealos.io/app-deploy-manager-domain: ${{ defaults.app_host }}
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/proxy-body-size: 32m
    nginx.ingress.kubernetes.io/server-snippet: |
      client_header_buffer_size 64k;
      large_client_header_buffers 4 128k;
    nginx.ingress.kubernetes.io/ssl-redirect: 'false'
    nginx.ingress.kubernetes.io/backend-protocol: HTTP
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    nginx.ingress.kubernetes.io/client-body-buffer-size: 64k
    nginx.ingress.kubernetes.io/proxy-buffer-size: 64k
    nginx.ingress.kubernetes.io/proxy-send-timeout: '300'
    nginx.ingress.kubernetes.io/proxy-read-timeout: '300'
    nginx.ingress.kubernetes.io/configuration-snippet: |
      if ($request_uri ~* \.(js|css|gif|jpe?g|png)) {
        expires 30d;
        add_header Cache-Control "public";
      }
spec:
  rules:
    - host: ${{ defaults.app_host }}.${{ SEALOS_CLOUD_DOMAIN }}
      http:
        paths:
          - pathType: Prefix
            path: /()(.*)
            backend:
              service:
                name: ${{ defaults.app_name }}
                port:
                  number: 5001
  tls:
    - hosts:
        - ${{ defaults.app_host }}.${{ SEALOS_CLOUD_DOMAIN }}
      secretName: ${{ SEALOS_CERT_SECRET_NAME }}