apiVersion: app.sealos.io/v1
kind: Template
metadata:
  name: laf
spec:
  title: "laf on sealos"
  url: "https://laf.run/"
  gitRepo: "https://github.com/labring/laf"
  author: "sealos"
  description: "Laf is a cloud development platform integrating functions, databases and storage Publish online anytime, anywhere"
  readme: "https://github.com/labring/laf/blob/main/README.md"
  icon: "https://laf.run/homepage/logo_icon.svg"
  templateType: inline
  defaults:
    app_name:
      type: string
      value: laf-${{ random(8) }}
    log_jwt:
      type: string
      value: ${{ random(32) }}
    server_jwt:
      type: string
      value: ${{ random(32) }}
    minio_passwd:
      type: string
      value: ${{ random(8) }}
  inputs:
    minio_storage:
      description: "Storage size for each server in Gi (4 servers in total)"
      type: number
      default: "1"
      required: true
    domain:
      description: "the domain of laf"
      type: string
      default: laf-${{ random(8) }}
      required: true
---
# mongo sa
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    sealos-db-provider-cr: ${{ defaults.app_name }}-mongo
    app.kubernetes.io/instance: ${{ defaults.app_name }}-mongo
    app.kubernetes.io/managed-by: kbcli
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}
  name: ${{ defaults.app_name }}-mongo

---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    sealos-db-provider-cr: ${{ defaults.app_name }}-mongo
    app.kubernetes.io/instance: ${{ defaults.app_name }}-mongo
    app.kubernetes.io/managed-by: kbcli
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}
  name: ${{ defaults.app_name }}-mongo
rules:
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    sealos-db-provider-cr: ${{ defaults.app_name }}-mongo
    app.kubernetes.io/instance: ${{ defaults.app_name }}-mongo
    app.kubernetes.io/managed-by: kbcli
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}
  name: ${{ defaults.app_name }}-mongo
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ${{ defaults.app_name }}-mongo
subjects:
  - kind: ServiceAccount
    name: ${{ defaults.app_name }}-mongo
    namespace: ${{ SEALOS_NAMESPACE}}
---
# mongodb
apiVersion: apps.kubeblocks.io/v1alpha1
kind: Cluster
metadata:
  finalizers:
    - cluster.kubeblocks.io/finalizer
  labels:
    clusterdefinition.kubeblocks.io/name: mongodb
    clusterversion.kubeblocks.io/name: mongodb-5.0.14
    sealos-db-provider-cr: ${{ defaults.app_name }}-mongo
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}
  annotations: {}
  name: ${{ defaults.app_name }}-mongo
  generation: 1
spec:
  affinity:
    nodeLabels: {}
    podAntiAffinity: Preferred
    tenancy: SharedNode
    topologyKeys: []
  clusterDefinitionRef: mongodb
  clusterVersionRef: mongodb-5.0.14
  componentSpecs:
    - componentDefRef: mongodb
      monitor: true
      name: mongodb
      replicas: 1
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 500m
          memory: 512Mi
      serviceAccountName: ${{ defaults.app_name }}-mongo
      volumeClaimTemplates:
        - name: data
          spec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 3Gi
            storageClassName: openebs-backup
  terminationPolicy: Delete
  tolerations: []

---
# laf sa
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-server
  name: ${{ defaults.app_name }}-sa

---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-server
  name: ${{ defaults.app_name }}-role
rules:
  - apiGroups:
      - "*"
    resources:
      - "*"
    verbs:
      - "*"

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-server
  name: ${{ defaults.app_name }}-rolebind
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ${{ defaults.app_name }}-role
subjects:
  - kind: ServiceAccount
    name: ${{ defaults.app_name }}-sa
    namespace: ${{ SEALOS_NAMESPACE}}

---
# laf-log
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-log
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-log
    app: ${{ defaults.app_name }}-log
  name: ${{ defaults.app_name }}-log
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ${{ defaults.app_name }}-log
  template:
    metadata:
      labels:
        app: ${{ defaults.app_name }}-log
    spec:
      containers:
        - image: docker.io/lafyun/log-server:latest
          imagePullPolicy: Always
          name: ${{ defaults.app_name }}-log
          ports:
            - name: http
              containerPort: 5060
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /healthz
              port: http
          readinessProbe:
            httpGet:
              path: /healthz
              port: http
          env:
            - name: MONGO_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: ${{ defaults.app_name }}-mongo-conn-credential
                  key: password
            - name: DB_URI
              value: "mongodb://root:$(MONGO_PASSWORD)@${{ defaults.app_name }}-mongo-mongodb.${{ SEALOS_NAMESPACE }}.svc:27017/function-logs?authSource=admin&w=majority"
            - name: JWT_SECRET
              value: ${{ defaults.log_jwt }}
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 300m
              memory: 512Mi
---
apiVersion: v1
kind: Service
metadata:
  labels:
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-log
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-log
  name: ${{ defaults.app_name }}-log
spec:
  ports:
    - name: http
      port: 5060
      protocol: TCP
      targetPort: http
  selector:
    app: ${{ defaults.app_name }}-log
---
# laf-server
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ${{ defaults.app_name }}-server
  labels:
    app: ${{ defaults.app_name }}-server
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-server
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ${{ defaults.app_name }}-server
  template:
    metadata:
      labels:
        app: ${{ defaults.app_name }}-server
    spec:
      automountServiceAccountToken: true
      serviceAccountName: ${{ defaults.app_name }}-sa
      securityContext: {}
      containers:
        - name: ${{ defaults.app_name }}-server
          securityContext: {}
          image: "docker.io/lafyun/laf-server:latest"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 3000
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /v1/regions
              port: http
          readinessProbe:
            httpGet:
              path: /v1/regions
              port: http
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 500m
              memory: 512Mi
          env:
            - name: DEFAULT_REGION_NAMESPACE
              value: ${{ SEALOS_NAMESPACE }}
            - name: MONGO_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: ${{ defaults.app_name }}-mongo-conn-credential
                  key: password
            - name: DATABASE_URL
              value: "mongodb://root:$(MONGO_PASSWORD)@${{ defaults.app_name }}-mongo-mongodb.${{ SEALOS_NAMESPACE }}.svc:27017/sys_db?authSource=admin&w=majority"
            - name: METERING_DATABASE_URL
              value: "mongodb://root:$(MONGO_PASSWORD)@${{ defaults.app_name }}-mongo-mongodb.${{ SEALOS_NAMESPACE }}.svc:27017/sealos-resources?authSource=admin&w=majority"
            - name: JWT_SECRET
              value: ${{ defaults.server_jwt }}
            - name: API_SERVER_URL
              value: "http://api.${{ inputs.domain }}.${{ SEALOS_CLOUD_DOMAIN }}"
            - name: JWT_EXPIRES_IN
              value: "7d"
            - name: DEFAULT_REGION_DATABASE_URL
              value: "mongodb://root:$(MONGO_PASSWORD)@${{ defaults.app_name }}-mongo-mongodb.${{ SEALOS_NAMESPACE }}.svc:27017/sys_db?authSource=admin&w=majority"
            - name: DEFAULT_REGION_MINIO_DOMAIN
              value: "oss.${{ inputs.domain }}.${{ SEALOS_CLOUD_DOMAIN }}"
            - name: DEFAULT_REGION_MINIO_EXTERNAL_ENDPOINT
              value: "http://oss.${{ inputs.domain }}.${{ SEALOS_CLOUD_DOMAIN }}"
            - name: DEFAULT_REGION_MINIO_INTERNAL_ENDPOINT
              value: "http://${{ defaults.app_name }}-minio.${{ SEALOS_NAMESPACE }}.svc.cluster.local:9000"
            - name: DEFAULT_REGION_MINIO_ROOT_ACCESS_KEY
              value: ${{ defaults.minio_passwd }}
            - name: DEFAULT_REGION_MINIO_ROOT_SECRET_KEY
              value: ${{ defaults.minio_passwd }}
            - name: DEFAULT_REGION_RUNTIME_DOMAIN
              value: "${{ inputs.domain }}.${{ SEALOS_CLOUD_DOMAIN }}"
            - name: DEFAULT_REGION_WEBSITE_DOMAIN
              value: "site.${{ inputs.domain }}.${{ SEALOS_CLOUD_DOMAIN }}"
            - name: DEFAULT_REGION_TLS
              value: "false"
            - name: DEFAULT_REGION_LOG_SERVER_URL
              value: "http://${{ defaults.app_name }}-log.${{ SEALOS_NAMESPACE }}.svc.cluster.local:5060"
            - name: DEFAULT_REGION_LOG_SERVER_SECRET
              value: ${{ defaults.log_jwt }}
            - name: DEFAULT_REGION_LOG_SERVER_DATABASE_URL
              value: "mongodb://root:$(MONGO_PASSWORD)@${{ defaults.app_name }}-mongo-mongodb.${{ SEALOS_NAMESPACE }}.svc:27017/function-logs?authSource=admin&w=majority"
            - name: DEFAULT_REGION_PROMETHEUS_URL
              value:
            - name: SITE_NAME
              value: "${{ inputs.domain }}.${{ SEALOS_CLOUD_DOMAIN }}"
---
apiVersion: v1
kind: Service
metadata:
  name: ${{ defaults.app_name }}-server
  labels:
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-server
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-server
spec:
  type: ClusterIP
  ports:
    - port: 3000
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app: ${{ defaults.app_name }}-server
---
# laf-web
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ${{ defaults.app_name }}-web
  labels:
    app: ${{ defaults.app_name }}-web
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-web
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-web
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ${{ defaults.app_name }}-web
  template:
    metadata:
      labels:
        app: ${{ defaults.app_name }}-web
    spec:
      serviceAccountName: default
      securityContext: {}
      containers:
        - name: ${{ defaults.app_name }}-web
          securityContext: {}
          image: "docker.io/lafyun/laf-web:latest"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 80
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: http
          readinessProbe:
            httpGet:
              path: /
              port: http
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 200m
              memory: 512Mi

---
apiVersion: v1
kind: Service
metadata:
  name: ${{ defaults.app_name }}-web
  labels:
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-web
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-web
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app: ${{ defaults.app_name }}-web

---
#laf minio
apiVersion: v1
kind: Secret
metadata:
  name: ${{ defaults.app_name }}-minio
  labels:
    app: ${{ defaults.app_name }}-minio
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-minio
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-minio
type: Opaque
stringData:
  rootUser: ${{ defaults.minio_passwd }}
  rootPassword: ${{ defaults.minio_passwd }}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ${{ defaults.app_name }}-minio
  labels:
    app: ${{ defaults.app_name }}-minio
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-minio
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-minio
data:
  initialize: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/etc/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"

    # connectToMinio
    # Use a check-sleep-check loop to wait for MinIO service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }

    # checkBucketExists ($bucket)
    # Check if the bucket exists, by using the exit code of `mc ls`
    checkBucketExists() {
      BUCKET=$1
      CMD=$(${MC} ls myminio/$BUCKET > /dev/null 2>&1)
      return $?
    }

    # createBucket ($bucket, $policy, $purge)
    # Ensure bucket exists, purging if asked to
    createBucket() {
      BUCKET=$1
      POLICY=$2
      PURGE=$3
      VERSIONING=$4
      OBJECTLOCKING=$5

      # Purge the bucket, if set & exists
      # Since PURGE is user input, check explicitly for `true`
      if [ $PURGE = true ]; then
        if checkBucketExists $BUCKET ; then
          echo "Purging bucket '$BUCKET'."
          set +e ; # don't exit if this fails
          ${MC} rm -r --force myminio/$BUCKET
          set -e ; # reset `e` as active
        else
          echo "Bucket '$BUCKET' does not exist, skipping purge."
        fi
      fi

    # Create the bucket if it does not exist and set objectlocking if enabled (NOTE: versioning will be not changed if OBJECTLOCKING is set because it enables versioning to the Buckets created)
    if ! checkBucketExists $BUCKET ; then
        if [ ! -z $OBJECTLOCKING ] ; then
          if [ $OBJECTLOCKING = true ] ; then
              echo "Creating bucket with OBJECTLOCKING '$BUCKET'"
              ${MC} mb --with-lock myminio/$BUCKET
          elif [ $OBJECTLOCKING = false ] ; then
                echo "Creating bucket '$BUCKET'"
                ${MC} mb myminio/$BUCKET
          fi
      elif [ -z $OBJECTLOCKING ] ; then
            echo "Creating bucket '$BUCKET'"
            ${MC} mb myminio/$BUCKET
      else
        echo "Bucket '$BUCKET' already exists."  
      fi
      fi


      # set versioning for bucket if objectlocking is disabled or not set
      if [ -z $OBJECTLOCKING ] ; then
      if [ ! -z $VERSIONING ] ; then
        if [ $VERSIONING = true ] ; then
            echo "Enabling versioning for '$BUCKET'"
            ${MC} version enable myminio/$BUCKET
        elif [ $VERSIONING = false ] ; then
            echo "Suspending versioning for '$BUCKET'"
            ${MC} version suspend myminio/$BUCKET
        fi
        fi
      else
          echo "Bucket '$BUCKET' versioning unchanged."
      fi


      # At this point, the bucket should exist, skip checking for existence
      # Set policy on the bucket
      echo "Setting policy of bucket '$BUCKET' to '$POLICY'."
      ${MC} anonymous set $POLICY myminio/$BUCKET
    }

    # Try connecting to MinIO instance
    scheme=http
    connectToMinio $scheme

  add-user: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/etc/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"

    # AccessKey and secretkey credentials file are added to prevent shell execution errors caused by special characters.
    # Special characters for example : ',",<,>,{,}
    MINIO_ACCESSKEY_SECRETKEY_TMP="/tmp/accessKey_and_secretKey_tmp"

    # connectToMinio
    # Use a check-sleep-check loop to wait for MinIO service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }

    # checkUserExists ()
    # Check if the user exists, by using the exit code of `mc admin user info`
    checkUserExists() {
      CMD=$(${MC} admin user info myminio $(head -1 $MINIO_ACCESSKEY_SECRETKEY_TMP) > /dev/null 2>&1)
      return $?
    }

    # createUser ($policy)
    createUser() {
      POLICY=$1
      #check accessKey_and_secretKey_tmp file
      if [[ ! -f $MINIO_ACCESSKEY_SECRETKEY_TMP ]];then
        echo "credentials file does not exist"
        return 1
      fi
      if [[ $(cat $MINIO_ACCESSKEY_SECRETKEY_TMP|wc -l) -ne 2 ]];then
        echo "credentials file is invalid"
        rm -f $MINIO_ACCESSKEY_SECRETKEY_TMP
        return 1
      fi
      USER=$(head -1 $MINIO_ACCESSKEY_SECRETKEY_TMP)
      # Create the user if it does not exist
      if ! checkUserExists ; then
        echo "Creating user '$USER'"
        cat $MINIO_ACCESSKEY_SECRETKEY_TMP | ${MC} admin user add myminio
      else
        echo "User '$USER' already exists."
      fi
      #clean up credentials files.
      rm -f $MINIO_ACCESSKEY_SECRETKEY_TMP

      # set policy for user
      if [ ! -z $POLICY -a $POLICY != " " ] ; then
          echo "Adding policy '$POLICY' for '$USER'"
          ${MC} admin policy set myminio $POLICY user=$USER
      else
          echo "User '$USER' has no policy attached."
      fi
    }

    # Try connecting to MinIO instance
    scheme=http
    connectToMinio $scheme

  add-policy: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/etc/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"

    # connectToMinio
    # Use a check-sleep-check loop to wait for MinIO service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }

    # checkPolicyExists ($policy)
    # Check if the policy exists, by using the exit code of `mc admin policy info`
    checkPolicyExists() {
      POLICY=$1
      CMD=$(${MC} admin policy info myminio $POLICY > /dev/null 2>&1)
      return $?
    }

    # createPolicy($name, $filename)
    createPolicy () {
      NAME=$1
      FILENAME=$2

      # Create the name if it does not exist
      echo "Checking policy: $NAME (in /config/$FILENAME.json)"
      if ! checkPolicyExists $NAME ; then
        echo "Creating policy '$NAME'"
      else
        echo "Policy '$NAME' already exists."
      fi
      ${MC} admin policy add myminio $NAME /config/$FILENAME.json

    }

    # Try connecting to MinIO instance
    scheme=http
    connectToMinio $scheme


    # Create the policies
    createPolicy laf_owner_by_prefix policy_0
    createPolicy laf_owner_readonly_by_prefix policy_1
  # laf_owner_by_prefix
  policy_0.json: |-
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Action": [
    "s3:GetBucketPolicy",
    "s3:GetObject",
    "s3:ListBucket",
    "s3:ListBucketMultipartUploads",
    "s3:ListMultipartUploadParts",
    "s3:PutObject",
    "s3:DeleteObject",
    "s3:GetBucketLocation"
          ],
          "Resource": [
    "arn:aws:s3:::${aws:username}-*"
          ] 
        }
      ]
    }

  # laf_owner_readonly_by_prefix
  policy_1.json: |-
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Action": [
    "s3:GetBucketPolicy",
    "s3:GetObject",
    "s3:ListBucket",
    "s3:ListBucketMultipartUploads",
    "s3:ListMultipartUploadParts",
    "s3:DeleteObject",
    "s3:GetBucketLocation"
          ],
          "Resource": [
    "arn:aws:s3:::${aws:username}-*"
          ] 
        }
      ]
    }

  custom-command: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/etc/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"

    # connectToMinio
    # Use a check-sleep-check loop to wait for MinIO service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }

    # runCommand ($@)
    # Run custom mc command
    runCommand() {
      ${MC} "$@"
      return $?
    }

    # Try connecting to MinIO instance
    scheme=http
    connectToMinio $scheme


    # Run custom commands
    runCommand alias ls && ls /config
    runCommand admin user add myminio temp-user abcd123456
    runCommand admin group add myminio laf_owner_by_prefix_group temp-user
    runCommand admin group add myminio laf_owner_readonly_by_prefix_group temp-user
    runCommand admin policy add myminio laf_owner_by_prefix /config/policy_0.json
    runCommand admin policy set myminio laf_owner_by_prefix group=laf_owner_by_prefix_group
    runCommand admin policy add myminio laf_owner_readonly_by_prefix /config/policy_1.json
    runCommand admin policy set myminio laf_owner_readonly_by_prefix group=laf_owner_readonly_by_prefix_group
---
apiVersion: v1
kind: Service
metadata:
  name: ${{ defaults.app_name }}-minio-console
  labels:
    app: ${{ defaults.app_name }}-minio
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-minio
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-minio
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 9001
      protocol: TCP
      targetPort: 9001
  selector:
    app: ${{ defaults.app_name }}-minio
---
apiVersion: v1
kind: Service
metadata:
  name: ${{ defaults.app_name }}-minio
  labels:
    app: ${{ defaults.app_name }}-minio
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-minio
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-minio
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 9000
      protocol: TCP
      targetPort: 9000
  selector:
    app: ${{ defaults.app_name }}-minio
---
apiVersion: v1
kind: Service
metadata:
  name: ${{ defaults.app_name }}-minio-svc
  labels:
    app: ${{ defaults.app_name }}-minio
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-minio
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-minio
spec:
  publishNotReadyAddresses: true
  clusterIP: None
  ports:
    - name: http
      port: 9000
      protocol: TCP
      targetPort: 9000
  selector:
    app: ${{ defaults.app_name }}-minio
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ${{ defaults.app_name }}-minio
  annotations:
    originImageName: quay.io/minio/minio
    deploy.cloud.sealos.io/minReplicas: "1"
    deploy.cloud.sealos.io/maxReplicas: "1"
  labels:
    app: ${{ defaults.app_name }}-minio
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-minio
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-minio
spec:
  replicas: 4
  serviceName: ${{ defaults.app_name }}-minio-svc
  selector:
    matchLabels:
      app: ${{ defaults.app_name }}-minio
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      name: ${{ defaults.app_name }}-minio
      labels:
        app: ${{ defaults.app_name }}-minio
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        fsGroupChangePolicy: OnRootMismatch
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      containers:
        - name: ${{ defaults.app_name }}-minio
          image: quay.io/minio/minio:RELEASE.2023-03-22T06-36-24Z
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          command:
            [
              "/bin/sh",
              "-ce",
              "/usr/bin/docker-entrypoint.sh minio server  http://${{ defaults.app_name }}-minio-{0...3}.${{ defaults.app_name }}-minio-svc.${{ SEALOS_NAMESPACE }}.svc.cluster.local/data -S /etc/minio/certs/ --address :9000 --console-address :9001",
            ]
          env:
            - name: MINIO_ROOT_USER
              valueFrom:
                secretKeyRef:
                  name: ${{ defaults.app_name }}-minio
                  key: rootUser
            - name: MINIO_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: ${{ defaults.app_name }}-minio
                  key: rootPassword
          ports:
            - name: http
              containerPort: 9000
            - name: http-console
              containerPort: 9001
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 200m
              memory: 256Mi
          volumeMounts:
            - name: data
              mountPath: /data
          livenessProbe:
            exec:
              command: ["curl", "-f", "http://localhost:9000/minio/health/live"]
            initialDelaySeconds: 5
            periodSeconds: 3
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 5
          readinessProbe:
            exec:
              command: ["curl", "-f", "http://localhost:9000/minio/health/live"]
            initialDelaySeconds: 5
            periodSeconds: 2
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 5
  volumeClaimTemplates:
    - metadata:
        annotations:
          path: /data
          value: "1"
        name: data
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: ${{ inputs.minio_storage }}Gi

---
# Source: minio/templates/post-install-create-policy-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: ${{ defaults.app_name }}-minio-make-policies-job
  labels:
    app: ${{ defaults.app_name }}-minio-make-policies-job
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-minio
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-minio
spec:
  ttlSecondsAfterFinished: 100
  template:
    metadata:
      labels:
        app: ${{ defaults.app_name }}-minio-make-policies-job
    spec:
      securityContext:
        runAsNonRoot: false
        seccompProfile:
          type: RuntimeDefault
      restartPolicy: OnFailure
      volumes:
        - name: minio-configuration
          projected:
            sources:
              - configMap:
                  name: ${{ defaults.app_name }}-minio
              - secret:
                  name: ${{ defaults.app_name }}-minio
      containers:
        - name: ${{ defaults.app_name }}-minio-mc
          image: "quay.io/minio/mc:RELEASE.2022-11-07T23-47-39Z"
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          command: ["/bin/sh", "/config/add-policy"]
          env:
            - name: MINIO_ENDPOINT
              value: "${{ defaults.app_name }}-minio.${{ SEALOS_NAMESPACE }}.svc.cluster.local"
            - name: MINIO_PORT
              value: "9000"
          volumeMounts:
            - name: minio-configuration
              mountPath: /config
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 200m
              memory: 128Mi
---
# Source: minio/templates/post-install-custom-command.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: ${{ defaults.app_name }}-minio-custom-command-job
  labels:
    app: ${{ defaults.app_name }}-minio-custom-command-job
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-minio
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-minio
spec:
  ttlSecondsAfterFinished: 100
  template:
    metadata:
      labels:
        app: ${{ defaults.app_name }}-minio-custom-command-job
    spec:
      securityContext:
        runAsNonRoot: false
        seccompProfile:
          type: RuntimeDefault
      restartPolicy: OnFailure
      volumes:
        - name: minio-configuration
          projected:
            sources:
              - configMap:
                  name: ${{ defaults.app_name }}-minio
              - secret:
                  name: ${{ defaults.app_name }}-minio
      containers:
        - name: ${{ defaults.app_name }}-minio-mc
          image: "quay.io/minio/mc:RELEASE.2022-11-07T23-47-39Z"
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          command: ["/bin/sh", "/config/custom-command"]
          env:
            - name: MINIO_ENDPOINT
              value: "${{ defaults.app_name }}-minio.${{ SEALOS_NAMESPACE }}.svc.cluster.local"
            - name: MINIO_PORT
              value: "9000"
          volumeMounts:
            - name: minio-configuration
              mountPath: /config
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 200m
              memory: 128Mi
---
# ingress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ${{ defaults.app_name }}-web
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-web
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-web
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/proxy-body-size: 32m
    nginx.ingress.kubernetes.io/server-snippet: |
      client_header_buffer_size 64k;
      large_client_header_buffers 4 128k;
    nginx.ingress.kubernetes.io/backend-protocol: HTTP
    nginx.ingress.kubernetes.io/client-body-buffer-size: 64k
    nginx.ingress.kubernetes.io/proxy-buffer-size: 64k
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/configuration-snippet: |
      if ($request_uri ~* \.(js|css|gif|jpe?g|png)) {
        expires 30d;
        add_header Cache-Control "public";
      }
spec:
  rules:
    - host: ${{ inputs.domain }}.${{ SEALOS_CLOUD_DOMAIN }}
      http:
        paths:
          - backend:
              service:
                name: ${{ defaults.app_name }}-web
                port:
                  number: 80
            path: /
            pathType: Prefix
          - backend:
              service:
                name: ${{ defaults.app_name }}-server
                port:
                  number: 3000
            path: /v1/
            pathType: Prefix
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ${{ defaults.app_name }}-server
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-server
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-server
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/proxy-body-size: 32m
    nginx.ingress.kubernetes.io/server-snippet: |
      client_header_buffer_size 64k;
      large_client_header_buffers 4 128k;
    nginx.ingress.kubernetes.io/backend-protocol: HTTP
    nginx.ingress.kubernetes.io/client-body-buffer-size: 64k
    nginx.ingress.kubernetes.io/proxy-buffer-size: 64k
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/configuration-snippet: |
      if ($request_uri ~* \.(js|css|gif|jpe?g|png)) {
        expires 30d;
        add_header Cache-Control "public";
      }
spec:
  rules:
    - host: api.${{ inputs.domain }}.${{ SEALOS_CLOUD_DOMAIN }}
      http:
        paths:
          - backend:
              service:
                name: ${{ defaults.app_name }}-server
                port:
                  number: 3000
            path: /
            pathType: Prefix

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ${{ defaults.app_name }}-minio-console
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-minio
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}-minio
    cloud.sealos.io/app-deploy-manager-domain: minio.${{ inputs.domain }}
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/proxy-body-size: 32m
    nginx.ingress.kubernetes.io/server-snippet: |
      client_header_buffer_size 64k;
      large_client_header_buffers 4 128k;
    nginx.ingress.kubernetes.io/backend-protocol: HTTP
    nginx.ingress.kubernetes.io/client-body-buffer-size: 64k
    nginx.ingress.kubernetes.io/proxy-buffer-size: 64k
    nginx.ingress.kubernetes.io/configuration-snippet: |
      if ($request_uri ~* \.(js|css|gif|jpe?g|png)) {
        expires 30d;
        add_header Cache-Control "public";
      }
spec:
  rules:
    - host: minio.${{ inputs.domain }}.${{ SEALOS_CLOUD_DOMAIN }}
      http:
        paths:
          - pathType: Prefix
            path: /
            backend:
              service:
                name: ${{ defaults.app_name }}-minio-console
                port:
                  number: 9001

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ${{ defaults.app_name }}-minio-api
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}
    cloud.sealos.io/deploy-on-sealos: ${{ defaults.app_name }}
    cloud.sealos.io/app-deploy-manager-domain: oss.${{ inputs.domain }}
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/proxy-body-size: 32m
    nginx.ingress.kubernetes.io/server-snippet: |
      client_header_buffer_size 64k;
      large_client_header_buffers 4 128k;
    nginx.ingress.kubernetes.io/backend-protocol: HTTP
    nginx.ingress.kubernetes.io/client-body-buffer-size: 64k
    nginx.ingress.kubernetes.io/proxy-buffer-size: 64k
    nginx.ingress.kubernetes.io/configuration-snippet: |
      if ($request_uri ~* \.(js|css|gif|jpe?g|png)) {
        expires 30d;
        add_header Cache-Control "public";
      }
spec:
  rules:
    - host: oss.${{ inputs.domain }}.${{ SEALOS_CLOUD_DOMAIN }}
      http:
        paths:
          - pathType: Prefix
            path: /
            backend:
              service:
                name: ${{ defaults.app_name }}-minio
                port:
                  number: 9000
