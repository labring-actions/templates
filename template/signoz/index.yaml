apiVersion: app.sealos.io/v1
kind: Template
metadata:
  name: signoz
spec:
  title: 'SigNoz'
  url: 'https://signoz.io/'
  gitRepo: 'https://github.com/SigNoz/signoz'
  author: 'sealos'
  description: 'SigNoz is an open-source observability platform native to OpenTelemetry with logs, traces and metrics in a single application. An open-source alternative to DataDog, NewRelic, etc.'
  readme: 'https://raw.githubusercontent.com/SigNoz/signoz/main/README.md'
  icon: 'https://avatars.githubusercontent.com/u/76905799?s=200&v=4'
  templateType: inline
  categories:
    - tool
    - database
  defaults:
    app_name:
      type: string
      value: signoz-${{ random(8) }}
    app_host:
      type: string
      value: ${{ random(8) }}
    app_host_otel_collector:
      type: string
      value: ${{ random(8) }}
  inputs:

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ${{ defaults.app_name }}-clickhouse
data:
  config.xml: |
    <?xml version="1.0"?>
    <clickhouse>
        <logger>
            <level>information</level>
            <formatting>
                <type>json</type>
            </formatting>
            <log>/var/log/clickhouse-server/clickhouse-server.log</log>
            <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
            <size>1000M</size>
            <count>10</count>
        </logger>
        <http_port>8123</http_port>
        <tcp_port>9000</tcp_port>
        <mysql_port>9004</mysql_port>
        <postgresql_port>9005</postgresql_port>
        <interserver_http_host>${{ defaults.app_name }}-clickhouse</interserver_http_host>
        <interserver_http_port>9009</interserver_http_port>
        <max_connections>4096</max_connections>
        <keep_alive_timeout>3</keep_alive_timeout>
        <max_concurrent_queries>100</max_concurrent_queries>
        <max_server_memory_usage>0</max_server_memory_usage>
        <max_thread_pool_size>10000</max_thread_pool_size>
        <max_server_memory_usage_to_ram_ratio>0.9</max_server_memory_usage_to_ram_ratio>
        <total_memory_profiler_step>4194304</total_memory_profiler_step>
        <total_memory_tracker_sample_probability>0</total_memory_tracker_sample_probability>
        <uncompressed_cache_size>8589934592</uncompressed_cache_size>
        <!-- https://clickhouse.com/docs/operations/tips -->
        <mark_cache_size>536870912</mark_cache_size>
        <mmap_cache_size>1000</mmap_cache_size>
        <compiled_expression_cache_size>134217728</compiled_expression_cache_size>
        <compiled_expression_cache_elements_size>10000</compiled_expression_cache_elements_size>
        <path>/var/lib/clickhouse/</path>
        <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>
        <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>
        <user_directories>
            <users_xml>
                <path>users.xml</path>
            </users_xml>
            <local_directory>
                <path>/var/lib/clickhouse/access/</path>
            </local_directory>
        </user_directories>
        <default_profile>default</default_profile>
        <custom_settings_prefixes></custom_settings_prefixes>
        <default_database>default</default_database>
        <mlock_executable>true</mlock_executable>
        <remap_executable>false</remap_executable>
        <macros>
            <shard>01</shard>
            <replica>example01-01-1</replica>
        </macros>
        <builtin_dictionaries_reload_interval>3600</builtin_dictionaries_reload_interval>
        <max_session_timeout>3600</max_session_timeout>
        <default_session_timeout>60</default_session_timeout>
        <query_log>
            <database>system</database>
            <table>query_log</table>
            <partition_by>toYYYYMM(event_date)</partition_by>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        </query_log>
        <trace_log>
            <database>system</database>
            <table>trace_log</table>
            <partition_by>toYYYYMM(event_date)</partition_by>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        </trace_log>
        <query_thread_log>
            <database>system</database>
            <table>query_thread_log</table>
            <partition_by>toYYYYMM(event_date)</partition_by>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        </query_thread_log>
        <query_views_log>
            <database>system</database>
            <table>query_views_log</table>
            <partition_by>toYYYYMM(event_date)</partition_by>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        </query_views_log>
        <part_log>
            <database>system</database>
            <table>part_log</table>
            <partition_by>toYYYYMM(event_date)</partition_by>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        </part_log>
        <metric_log>
            <database>system</database>
            <table>metric_log</table>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
            <collect_interval_milliseconds>1000</collect_interval_milliseconds>
        </metric_log>
        <asynchronous_metric_log>
            <database>system</database>
            <table>asynchronous_metric_log</table>
            <flush_interval_milliseconds>7000</flush_interval_milliseconds>
        </asynchronous_metric_log>
        <opentelemetry_span_log>
            <engine>
                engine MergeTree
                partition by toYYYYMM(finish_date)
                order by (finish_date, finish_time_us, trace_id)
            </engine>
            <database>system</database>
            <table>opentelemetry_span_log</table>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        </opentelemetry_span_log>
        <crash_log>
            <database>system</database>
            <table>crash_log</table>
            <partition_by />
            <flush_interval_milliseconds>1000</flush_interval_milliseconds>
        </crash_log>
        <processors_profile_log>
            <database>system</database>
            <table>processors_profile_log</table>
            <partition_by>toYYYYMM(event_date)</partition_by>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        </processors_profile_log>
        <dictionaries_config>*_dictionary.xml</dictionaries_config>
        <user_defined_executable_functions_config>*function.xml</user_defined_executable_functions_config>
        <user_scripts_path>/var/lib/clickhouse/user_scripts/</user_scripts_path>
        <distributed_ddl>
          <path>/clickhouse/task_queue/ddl</path>
        </distributed_ddl>
        <graphite_rollup_example>
            <pattern>
                <regexp>click_cost</regexp>
                <function>any</function>
                <retention>
                    <age>0</age>
                    <precision>3600</precision>
                </retention>
                <retention>
                    <age>86400</age>
                    <precision>60</precision>
                </retention>
            </pattern>
            <default>
                <function>max</function>
                <retention>
                    <age>0</age>
                    <precision>60</precision>
                </retention>
                <retention>
                    <age>3600</age>
                    <precision>300</precision>
                </retention>
                <retention>
                    <age>86400</age>
                    <precision>3600</precision>
                </retention>
            </default>
        </graphite_rollup_example>
        <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>
        <query_masking_rules>
            <rule>
                <name>hide encrypt/decrypt arguments</name>
                <regexp>((?:aes_)?(?:encrypt|decrypt)(?:_mysql)?)\s*\(\s*(?:'(?:\\'|.)+'|.*?)\s*\)</regexp>
                <replace>\1(???)</replace>
            </rule>
        </query_masking_rules>
        <merge_tree_metadata_cache>
            <lru_cache_size>268435456</lru_cache_size>
            <continue_if_corrupted>true</continue_if_corrupted>
        </merge_tree_metadata_cache>

        <listen_host>0.0.0.0</listen_host>
    </clickhouse>
  users.xml: |
    <?xml version="1.0"?>
    <clickhouse>
        <profiles>
            <default>
                <max_memory_usage>10000000000</max_memory_usage>
                <load_balancing>random</load_balancing>
            </default>
            <readonly>
              <readonly>1</readonly>
            </readonly>
        </profiles>
        <users>
            <default>
                <password></password>
                <profile>default</profile>
                <networks>
                    <ip>::/0</ip>
                </networks>
                <quota>default</quota>
            </default>
        </users>
        <quotas>
            <default>
                <interval>
                    <duration>3600</duration>
                    <queries>0</queries>
                    <errors>0</errors>
                    <result_rows>0</result_rows>
                    <read_rows>0</read_rows>
                    <execution_time>0</execution_time>
                </interval>
            </default>
        </quotas>
    </clickhouse>
  custom-function.xml: |
    <functions>
        <function>
            <type>executable</type>
            <name>histogramQuantile</name>
            <return_type>Float64</return_type>
            <argument>
                <type>Array(Float64)</type>
                <name>buckets</name>
            </argument>
            <argument>
                <type>Array(Float64)</type>
                <name>counts</name>
            </argument>
            <argument>
                <type>Float64</type>
                <name>quantile</name>
            </argument>
            <format>CSV</format>
            <command>/var/lib/clickhouse/user_scripts/histogramQuantile</command>
        </function>
    </functions>
  cluster.xml: |
    <?xml version="1.0"?>
    <clickhouse>
        <zookeeper>
            <node index="1">
                <host>${{ defaults.app_name }}-zookeeper-0</host>
                <port>2181</port>
            </node>
        </zookeeper>
        <remote_servers>
            <cluster>
                <shard>
                    <replica>
                        <host>${{ defaults.app_name }}-clickhouse-0</host>
                        <port>9000</port>
                    </replica>
                </shard>
            </cluster>
        </remote_servers>
    </clickhouse>

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ${{ defaults.app_name }}-signoz
data:
  prometheus.yml: |
    global:
      scrape_interval: 5s
      evaluation_interval: 15s
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          - alertmanager:9093
    rule_files: []
    scrape_configs: []
    remote_read:
      - url: tcp://${{ defaults.app_name }}-clickhouse-0:9000/signoz_metrics
  otel-collector-config.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      prometheus:
        config:
          global:
            scrape_interval: 60s
          scrape_configs:
            - job_name: otel-collector
              static_configs:
              - targets:
                  - localhost:8888
                labels:
                  job_name: otel-collector
    processors:
      batch:
        send_batch_size: 10000
        send_batch_max_size: 11000
        timeout: 10s
      resourcedetection:
        detectors: [env, system]
        timeout: 2s
      signozspanmetrics/delta:
        metrics_exporter: clickhousemetricswrite, signozclickhousemetrics
        metrics_flush_interval: 60s
        latency_histogram_buckets: [100us, 1ms, 2ms, 6ms, 10ms, 50ms, 100ms, 250ms, 500ms, 1000ms, 1400ms, 2000ms, 5s, 10s, 20s, 40s, 60s ]
        dimensions_cache_size: 100000
        aggregation_temporality: AGGREGATION_TEMPORALITY_DELTA
        enable_exp_histogram: true
        dimensions:
          - name: service.namespace
            default: default
          - name: deployment.environment
            default: default
          - name: signoz.collector.id
          - name: service.version
          - name: browser.platform
          - name: browser.mobile
          - name: k8s.cluster.name
          - name: k8s.node.name
          - name: k8s.namespace.name
          - name: host.name
          - name: host.type
          - name: container.name
    extensions:
      health_check:
        endpoint: 0.0.0.0:13133
      pprof:
        endpoint: 0.0.0.0:1777
    exporters:
      clickhousetraces:
        datasource: tcp://${{ defaults.app_name }}-clickhouse-0:9000/signoz_traces
        low_cardinal_exception_grouping: ${env:LOW_CARDINAL_EXCEPTION_GROUPING}
        use_new_schema: true
      clickhousemetricswrite:
        endpoint: tcp://${{ defaults.app_name }}-clickhouse-0:9000/signoz_metrics
        disable_v2: true
        resource_to_telemetry_conversion:
          enabled: true
      clickhousemetricswrite/prometheus:
        endpoint: tcp://${{ defaults.app_name }}-clickhouse-0:9000/signoz_metrics
        disable_v2: true
      signozclickhousemetrics:
        dsn: tcp://${{ defaults.app_name }}-clickhouse-0:9000/signoz_metrics
      clickhouselogsexporter:
        dsn: tcp://${{ defaults.app_name }}-clickhouse-0:9000/signoz_logs
        timeout: 10s
        use_new_schema: true
    service:
      telemetry:
        logs:
          encoding: json
        metrics:
          address: 0.0.0.0:8888
      extensions:
        - health_check
        - pprof
      pipelines:
        traces:
          receivers: [otlp]
          processors: [signozspanmetrics/delta, batch]
          exporters: [clickhousetraces]
        metrics:
          receivers: [otlp]
          processors: [batch]
          exporters: [clickhousemetricswrite, signozclickhousemetrics]
        metrics/prometheus:
          receivers: [prometheus]
          processors: [batch]
          exporters: [clickhousemetricswrite/prometheus, signozclickhousemetrics]
        logs:
          receivers: [otlp]
          processors: [batch]
          exporters: [clickhouselogsexporter]
  otel-collector-opamp-config.yaml: |
    server_endpoint: ws://${{ defaults.app_name }}:4320/v1/opamp

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ${{ defaults.app_name }}-zookeeper
  annotations:
    originImageName: bitnami/zookeeper:3.7.1
    deploy.cloud.sealos.io/minReplicas: '1'
    deploy.cloud.sealos.io/maxReplicas: '1'
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-zookeeper
    app: ${{ defaults.app_name }}-zookeeper
spec:
  replicas: 1
  revisionHistoryLimit: 1
  serviceName: ${{ defaults.app_name }}-zookeeper
  selector:
    matchLabels:
      app: ${{ defaults.app_name }}-zookeeper
  template:
    metadata:
      labels:
        app: ${{ defaults.app_name }}-zookeeper
        signoz.io/scrape: "true"
        signoz.io/port: "9141"
        signoz.io/path: "metrics"
    spec:
      terminationGracePeriodSeconds: 10
      automountServiceAccountToken: false
      initContainers:
      - name: volume-permissions
        image: busybox
        command: ["sh", "-c", "chown -R 1001:1001 /bitnami/zookeeper"]
        volumeMounts:
        - name: vn-bitnamivn-zookeeper
          mountPath: /bitnami/zookeeper
      containers:
      - name: ${{ defaults.app_name }}-zookeeper
        image: bitnami/zookeeper:3.7.1
        ports:
        - containerPort: 2181
          name: client
        - containerPort: 2888
          name: server
        - containerPort: 3888
          name: leader-election
        - containerPort: 9141
          name: metrics
        env:
        - name: ZOO_SERVER_ID
          value: "1"
        - name: ALLOW_ANONYMOUS_LOGIN
          value: "yes"
        - name: ZOO_AUTOPURGE_INTERVAL
          value: "1"
        - name: ZOO_ENABLE_PROMETHEUS_METRICS
          value: "yes"
        - name: ZOO_PROMETHEUS_METRICS_PORT_NUMBER
          value: "9141"
        volumeMounts:
        - name: vn-bitnamivn-zookeeper
          mountPath: /bitnami/zookeeper
        resources:
          limits:
            cpu: 1
            memory: 1Gi
          requests:
            cpu: 100m
            memory: 100Mi
  volumeClaimTemplates:
  - metadata:
      annotations:
        path: /bitnami/zookeeper
        value: '1'
      name: vn-bitnamivn-zookeeper
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 1Gi

---
apiVersion: v1
kind: Service
metadata:
  name: ${{ defaults.app_name }}-zookeeper-0
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-zookeeper
spec:
  ports:
  - port: 2181
    name: client
  - port: 2888
    name: server
  - port: 3888
    name: leader-election
  - port: 9141
    name: metrics
  selector:
    app: ${{ defaults.app_name }}-zookeeper

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ${{ defaults.app_name }}-clickhouse
  annotations:
    originImageName: clickhouse/clickhouse-server:24.1.2-alpine
    deploy.cloud.sealos.io/minReplicas: '1'
    deploy.cloud.sealos.io/maxReplicas: '1'
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-clickhouse
    app: ${{ defaults.app_name }}-clickhouse
spec:
  replicas: 1
  revisionHistoryLimit: 1
  serviceName: ${{ defaults.app_name }}-clickhouse
  selector:
    matchLabels:
      app: ${{ defaults.app_name }}-clickhouse
  template:
    metadata:
      labels:
        app: ${{ defaults.app_name }}-clickhouse
        signoz.io/scrape: "true"
        signoz.io/port: "9363"
        signoz.io/path: "metrics"
    spec:
      initContainers:
      - name: init-clickhouse
        image: clickhouse/clickhouse-server:24.1.2-alpine
        command:
        - bash
        - -c
        - |
          if [ -f /var/lib/clickhouse/user_scripts/histogramQuantile ]; then
              mkdir -p /var/lib/clickhouse/user_scripts
              version="v0.0.1"
              node_arch=$$(uname -m | sed s/aarch64/arm64/ | sed s/x86_64/amd64/)
              echo "Fetching histogram-binary for $${node_arch}"
              cd /tmp
              wget -O histogram-quantile.tar.gz "https://github.com/SigNoz/signoz/releases/download/histogram-quantile/$${version}/histogram-quantile_linux_$${node_arch}.tar.gz"
              tar -xvzf histogram-quantile.tar.gz
              mv histogram-quantile /var/lib/clickhouse/user_scripts/histogramQuantile
          fi
        volumeMounts:
        - name: vn-varvn-libvn-clickhouse
          mountPath: /var/lib/clickhouse
      - name: wait-for-zookeeper
        image: busybox:1.28
        command: ['sh', '-c', 'until nc -z ${{ defaults.app_name }}-zookeeper-0 2181; do echo waiting for zookeeper; sleep 2; done;']
      containers:
      - name: clickhouse
        image: clickhouse/clickhouse-server:24.1.2-alpine
        ports:
        - containerPort: 8123
          name: http
        - containerPort: 9000
          name: tcp
        - containerPort: 9009
          name: interserver
        - containerPort: 9363
          name: metrics
        volumeMounts:
        - name: clickhouse-config
          mountPath: /etc/clickhouse-server/config.xml
          subPath: config.xml
        - name: clickhouse-config
          mountPath: /etc/clickhouse-server/users.xml
          subPath: users.xml
        - name: clickhouse-config
          mountPath: /etc/clickhouse-server/custom-function.xml
          subPath: custom-function.xml
        - name: clickhouse-config
          mountPath: /etc/clickhouse-server/config.d/cluster.xml
          subPath: cluster.xml
        - name: vn-varvn-libvn-clickhouse
          mountPath: /var/lib/clickhouse
        - name: vn-varvn-logvn-clickhouse-server
          mountPath: /var/log/clickhouse-server
        resources:
          limits:
            cpu: 2
            memory: 4Gi
          requests:
            cpu: 200m
            memory: 400Mi
        livenessProbe:
          httpGet:
            path: /ping
            port: 8123
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ping
            port: 8123
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 5
          failureThreshold: 3
      volumes:
      - name: clickhouse-config
        configMap:
          name: ${{ defaults.app_name }}-clickhouse
  volumeClaimTemplates:
  - metadata:
      name: vn-varvn-libvn-clickhouse
      annotations:
        path: /var/lib/clickhouse
        value: '10'
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
  - metadata:
      name: vn-varvn-logvn-clickhouse-server
      annotations:
        path: /var/log/clickhouse-server
        value: '3'
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 3Gi

---
apiVersion: v1
kind: Service
metadata:
  name: ${{ defaults.app_name }}-clickhouse-0
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-clickhouse
    app: ${{ defaults.app_name }}-clickhouse
spec:
  ports:
  - port: 8123
    name: http
  - port: 9000
    name: tcp
  - port: 9009
    name: interserver
  - port: 9363
    name: metrics
  selector:
    app: ${{ defaults.app_name }}-clickhouse

---
apiVersion: batch/v1
kind: Job
metadata:
  name: ${{ defaults.app_name }}-schema-migrator
spec:
  template:
    spec:
      automountServiceAccountToken: false
      initContainers:
        - name: wait-for-clickhouse
          image: busybox:1.28
          command: ['sh', '-c', 'until nc -z ${{ defaults.app_name }}-clickhouse-0 9000; do echo waiting for clickhouse; sleep 2; done;']
        - name: schema-migrator-sync
          image: signoz/signoz-schema-migrator:v0.111.41
          args:
            - sync
            - --dev=true
            - --dsn=tcp://${{ defaults.app_name }}-clickhouse-0:9000
            - --up=
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 50m
              memory: 51Mi
        - name: schema-migrator-async
          image: signoz/signoz-schema-migrator:v0.111.41
          args:
            - async
            - --dsn=tcp://${{ defaults.app_name }}-clickhouse-0:9000
            - --up=
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 50m
              memory: 51Mi
      containers:
        - name: ${{ defaults.app_name }}-schema-migrator-done
          image: busybox:1.28
          command: ['sh', '-c', 'echo done;']
      restartPolicy: OnFailure

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ${{ defaults.app_name }}
  annotations:
    originImageName: signoz/signoz:v0.85.0
    deploy.cloud.sealos.io/minReplicas: '1'
    deploy.cloud.sealos.io/maxReplicas: '1'
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}
    app: ${{ defaults.app_name }}
spec:
  replicas: 1
  revisionHistoryLimit: 1
  serviceName: ${{ defaults.app_name }}
  selector:
    matchLabels:
      app: ${{ defaults.app_name }}
  template:
    metadata:
      labels:
        app: ${{ defaults.app_name }}
    spec:
      automountServiceAccountToken: false
      containers:
      - name: ${{ defaults.app_name }}
        image: signoz/signoz:v0.85.0
        args:
        - --config=/root/config/prometheus.yml
        ports:
        - containerPort: 8080
          name: http
        - containerPort: 4320
          name: server
        volumeMounts:
        - name: signoz-config
          mountPath: /root/config/prometheus.yml
          subPath: prometheus.yml
        - name: vn-varvn-libvn-signoz
          mountPath: /var/lib/signoz
        env:
        - name: SIGNOZ_ALERTMANAGER_PROVIDER
          value: signoz
        - name: SIGNOZ_TELEMETRYSTORE_CLICKHOUSE_DSN
          value: tcp://${{ defaults.app_name }}-clickhouse-0:9000
        - name: SIGNOZ_SQLSTORE_SQLITE_PATH
          value: /var/lib/signoz/signoz.db
        - name: DASHBOARDS_PATH
          value: /root/config/dashboards
        - name: STORAGE
          value: clickhouse
        - name: GODEBUG
          value: netdns=go
        - name: TELEMETRY_ENABLED
          value: 'false'
        - name: DEPLOYMENT_TYPE
          value: 'kubernetes'
        resources:
          limits:
            cpu: 1000m
            memory: 1Gi
          requests:
            cpu: 100m
            memory: 100Mi
        livenessProbe:
          httpGet:
            path: /api/v1/health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /api/v1/health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 5
          failureThreshold: 3
      volumes:
      - name: signoz-config
        configMap:
          name: ${{ defaults.app_name }}-signoz
  volumeClaimTemplates:
    - metadata:
        name: vn-varvn-libvn-signoz
        annotations:
          path: /var/lib/signoz
          value: '1'
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 1Gi

---
apiVersion: v1
kind: Service
metadata:
  name: ${{ defaults.app_name }}
  labels:
    app: ${{ defaults.app_name }}
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}
spec:
  ports:
  - port: 8080
    name: http
  - port: 4320
    name: server
  selector:
    app: ${{ defaults.app_name }}

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ${{ defaults.app_name }}-otel-collector
  annotations:
    originImageName: signoz/signoz-otel-collector:v0.111.41
    deploy.cloud.sealos.io/minReplicas: '1'
    deploy.cloud.sealos.io/maxReplicas: '1'
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-otel-collector
    app: ${{ defaults.app_name }}-otel-collector
spec:
  replicas: 1
  revisionHistoryLimit: 1
  selector:
    matchLabels:
      app: ${{ defaults.app_name }}-otel-collector
  template:
    metadata:
      labels:
        app: ${{ defaults.app_name }}-otel-collector
    spec:
      containers:
      - name: otel-collector
        image: signoz/signoz-otel-collector:v0.111.41
        command:
        - /signoz-otel-collector
        - --config=/etc/otel-collector-config.yaml
        - --manager-config=/etc/manager-config.yaml
        - --copy-path=/var/tmp/collector-config.yaml
        - --feature-gates=-pkg.translator.prometheus.NormalizeName
        ports:
        - containerPort: 4317
          name: otlp-grpc
        - containerPort: 4318
          name: otlp-http
        - containerPort: 8888
          name: metrics
        volumeMounts:
        - name: signoz-config
          mountPath: /etc/otel-collector-config.yaml
          subPath: otel-collector-config.yaml
        - name: signoz-config
          mountPath: /etc/manager-config.yaml
          subPath: otel-collector-opamp-config.yaml
        env:
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: host.name=signoz-host,os.type=linux
        - name: LOW_CARDINAL_EXCEPTION_GROUPING
          value: "false"
        resources:
          limits:
            cpu: 1
            memory: 1Gi
          requests:
            cpu: 100m
            memory: 100Mi
      volumes:
      - name: signoz-config
        configMap:
          name: ${{ defaults.app_name }}-signoz

---
apiVersion: v1
kind: Service
metadata:
  name: ${{ defaults.app_name }}-otel-collector
  labels:
    app: ${{ defaults.app_name }}-otel-collector
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-otel-collector
spec:
  ports:
  - port: 4317
    name: otlp-grpc
  - port: 4318
    name: otlp-http
  - port: 8888
    name: metrics
  selector:
    app: ${{ defaults.app_name }}-otel-collector

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ${{ defaults.app_name }}-otel-collector
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}-otel-collector
    cloud.sealos.io/app-deploy-manager-domain: ${{ defaults.app_host_otel_collector }}
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  rules:
    - host: ${{ defaults.app_host_otel_collector }}.${{ SEALOS_CLOUD_DOMAIN }}
      http:
        paths:
          - pathType: Prefix
            path: /
            backend:
              service:
                name: ${{ defaults.app_name }}-otel-collector
                port:
                  number: 4318
  tls:
    - hosts:
        - ${{ defaults.app_host_otel_collector }}.${{ SEALOS_CLOUD_DOMAIN }}
      secretName: ${{ SEALOS_CERT_SECRET_NAME }}

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ${{ defaults.app_name }}
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}
    cloud.sealos.io/app-deploy-manager-domain: ${{ defaults.app_host }}
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  rules:
    - host: ${{ defaults.app_host }}.${{ SEALOS_CLOUD_DOMAIN }}
      http:
        paths:
          - pathType: Prefix
            path: /
            backend:
              service:
                name: ${{ defaults.app_name }}
                port:
                  number: 8080
  tls:
    - hosts:
        - ${{ defaults.app_host }}.${{ SEALOS_CLOUD_DOMAIN }}
      secretName: ${{ SEALOS_CERT_SECRET_NAME }}

---
apiVersion: app.sealos.io/v1
kind: App
metadata:
  name: ${{ defaults.app_name }}
  labels:
    cloud.sealos.io/app-deploy-manager: ${{ defaults.app_name }}
spec:
  data:
    url: https://${{ defaults.app_host }}.${{ SEALOS_CLOUD_DOMAIN }}
  displayType: normal
  icon: "https://avatars.githubusercontent.com/u/76905799?s=200&v=4"
  name: ${{ defaults.app_name }}
  type: link